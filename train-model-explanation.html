<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>train_model.py Explanation - Smart Credit Risk System</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ›¡ï¸</text></svg>">
    
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <!-- Sidebar Navigation -->
    <nav class="sidebar" id="sidebar">
        <div class="sidebar-header">
            <h1>Smart Credit Risk System</h1>
            <p>ML Documentation</p>
        </div>
        <ul class="sidebar-nav">
            <li><a href="index.html">ğŸ  Home</a></li>
            <li><a href="backend.html">âš™ï¸ Backend Walkthrough</a></li>
            <li><a href="app-explanation.html">ğŸ“ app.py Explanation</a></li>
            <li><a href="notebook-explanation.html">ğŸ““ Notebook Explanation</a></li>
    
            <li><a href="train-model-explanation.html" class="active">ğŸ¤– train_model.py</a></li>
            <li><a href="shrink-model-explanation.html">ğŸ—œï¸ shrink_model.py</a></li>
            <li><a href="interface.html">ğŸ’» Interface & Deployment</a></li>
            <li><a href="tools.html">ğŸ› ï¸ Tools & Dataset</a></li>
            <li><a href="faq.html">â“ FAQ & Interview Q&A</a></li>
        </ul>
    </nav>

    <!-- Mobile Menu Toggle -->
    <button class="mobile-menu-toggle" onclick="toggleSidebar()">â˜°</button>

    <!-- Main Content -->
    <main class="main-content">
        <div class="page-header">
            <h1>train_model.py - Complete Training Script</h1>
            <p>A standalone Python script to train the Random Forest model from scratch</p>
        </div>

        <!-- Overview -->
        <div class="content-section">
            <h2>Overview</h2>
            <p>
                The <code>train_model.py</code> script is a complete, standalone training script that loads data, 
                preprocesses it, trains a Random Forest model, and saves it. This script can be run independently 
                to retrain the model on your local machine.
            </p>
            <div class="highlight-box">
                <h3>ğŸ¯ Purpose</h3>
                <p>Train a Random Forest Classifier model from scratch using the Credit Risk Dataset, with proper 
                preprocessing, feature engineering, and handling of imbalanced data.</p>
            </div>
        </div>

        <!-- Complete Code -->
        <div class="content-section">
            <h2>Complete Code</h2>
            <div class="code-block">
<code><span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">import</span> joblib
<span class="keyword">import</span> os

<span class="comment"># Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª</span>
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split
<span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, OneHotEncoder
<span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer
<span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline
<span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier

print(<span class="string">"â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ..."</span>)

<span class="comment"># 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</span>
df = pd.read_csv(<span class="string">"credit_risk_dataset.csv"</span>)

<span class="comment"># 2. ØªÙ†Ø¸ÙŠÙ ÙˆÙ‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª</span>
df = df[df[<span class="string">'person_age'</span>] <= <span class="string">100</span>] <span class="comment"># Ø­Ø°Ù Ø§Ù„Ø´ÙˆØ§Ø°</span>
df[<span class="string">'interest_burden'</span>] = (df[<span class="string">'loan_amnt'</span>] * (df[<span class="string">'loan_int_rate'</span>] / <span class="string">100</span>)) / df[<span class="string">'person_income'</span>]
df[<span class="string">'interest_burden'</span>] = df[<span class="string">'interest_burden'</span>].fillna(<span class="string">0</span>)

<span class="comment"># 3. Ø§Ù„ØªÙ‚Ø³ÙŠÙ…</span>
X = df.drop(<span class="string">'loan_status'</span>, axis=<span class="string">1</span>)
y = df[<span class="string">'loan_status'</span>]

<span class="comment"># 4. Ø§Ù„ØªØ¬Ù‡ÙŠØ² (Pipeline)</span>
numeric_features = X.select_dtypes(include=[<span class="string">'int64'</span>, <span class="string">'float64'</span>]).columns
categorical_features = X.select_dtypes(include=[<span class="string">'object'</span>, <span class="string">'category'</span>]).columns

numeric_transformer = Pipeline(steps=[
    (<span class="string">'imputer'</span>, SimpleImputer(strategy=<span class="string">'median'</span>)),
    (<span class="string">'scaler'</span>, StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    (<span class="string">'imputer'</span>, SimpleImputer(strategy=<span class="string">'most_frequent'</span>)),
    (<span class="string">'onehot'</span>, OneHotEncoder(handle_unknown=<span class="string">'ignore'</span>))
])

preprocessor = ColumnTransformer(
    transformers=[
        (<span class="string">'num'</span>, numeric_transformer, numeric_features),
        (<span class="string">'cat'</span>, categorical_transformer, categorical_features)
    ])

<span class="comment"># 5. Ø§Ù„ØªØ¯Ø±ÙŠØ¨</span>
model = Pipeline(steps=[
    (<span class="string">'preprocessor'</span>, preprocessor),
    (<span class="string">'classifier'</span>, RandomForestClassifier(n_estimators=<span class="string">100</span>, class_weight=<span class="string">'balanced'</span>, random_state=<span class="string">42</span>))
])

model.fit(X, y)

<span class="comment"># 6. Ø§Ù„Ø­ÙØ¸</span>
joblib.dump(model, <span class="string">'credit_risk_model.pkl'</span>)

print(<span class="string">"âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ù…Ù„Ù 'credit_risk_model.pkl' Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!"</span>)
print(<span class="string">"Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ´ØºÙŠÙ„ app.py Ø¨Ø¯ÙˆÙ† Ù…Ø´Ø§ÙƒÙ„."</span>)</code>
            </div>
        </div>

        <!-- Table of Contents -->
        <div class="content-section">
            <h2>ğŸ“š Table of Contents</h2>
            <ul style="columns: 2; column-gap: 2rem;">
                <li><a href="#section1" style="color: var(--navy-blue); text-decoration: none;">1. Library Imports</a></li>
                <li><a href="#section2" style="color: var(--navy-blue); text-decoration: none;">2. Load Data</a></li>
                <li><a href="#section3" style="color: var(--navy-blue); text-decoration: none;">3. Data Cleaning & Feature Engineering</a></li>
                <li><a href="#section4" style="color: var(--navy-blue); text-decoration: none;">4. Data Splitting</a></li>
                <li><a href="#section5" style="color: var(--navy-blue); text-decoration: none;">5. Preprocessing Pipeline</a></li>
                <li><a href="#section6" style="color: var(--navy-blue); text-decoration: none;">6. Model Training</a></li>
                <li><a href="#section7" style="color: var(--navy-blue); text-decoration: none;">7. Model Saving</a></li>
            </ul>
        </div>

        <!-- Section 1: Imports -->
        <div class="content-section" id="section1">
            <h2>1ï¸âƒ£ Library Imports</h2>
            <div class="code-block">
<code><span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">import</span> joblib
<span class="keyword">import</span> os

<span class="comment"># Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª</span>
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split
<span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, OneHotEncoder
<span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer
<span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline
<span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</code>
            </div>

            <h3>What Each Library Does:</h3>
            <div class="info-box">
                <ul>
                    <li><strong>pandas:</strong> Load and manipulate the dataset</li>
                    <li><strong>joblib:</strong> Save the trained model to a file</li>
                    <li><strong>os:</strong> Operating system interface (used implicitly)</li>
                    <li><strong>sklearn:</strong> All Machine Learning tools (preprocessing, models, etc.)</li>
                </ul>
            </div>
        </div>

        <!-- Section 2: Load Data -->
        <div class="content-section" id="section2">
            <h2>2ï¸âƒ£ Load Data</h2>
            <div class="code-block">
<code>print(<span class="string">"â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ..."</span>)

<span class="comment"># 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</span>
df = pd.read_csv(<span class="string">"credit_risk_dataset.csv"</span>)</code>
            </div>

            <div class="info-box">
                <h3>What This Does:</h3>
                <ul>
                    <li><strong>Print Message:</strong> Shows a user-friendly message in Arabic: "Loading data and training the model on your device..."</li>
                    <li><strong>Load CSV:</strong> Reads the dataset from <code>credit_risk_dataset.csv</code> file</li>
                    <li>The file must be in the same directory as the script</li>
                </ul>
            </div>

            <div class="highlight-box">
                <h3>ğŸ“Š Dataset Requirements:</h3>
                <ul>
                    <li>File name: <code>credit_risk_dataset.csv</code></li>
                    <li>Location: Same folder as <code>train_model.py</code></li>
                    <li>Format: CSV (Comma-Separated Values)</li>
                    <li>Expected columns: person_age, person_income, loan_status, etc.</li>
                </ul>
            </div>
        </div>

        <!-- Section 3: Data Cleaning & Feature Engineering -->
        <div class="content-section" id="section3">
            <h2>3ï¸âƒ£ Data Cleaning & Feature Engineering â­</h2>
            <div class="code-block">
<code><span class="comment"># 2. ØªÙ†Ø¸ÙŠÙ ÙˆÙ‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª</span>
df = df[df[<span class="string">'person_age'</span>] <= <span class="string">100</span>] <span class="comment"># Ø­Ø°Ù Ø§Ù„Ø´ÙˆØ§Ø°</span>

<span class="comment"># Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©</span>
df[<span class="string">'interest_burden'</span>] = (df[<span class="string">'loan_amnt'</span>] * (df[<span class="string">'loan_int_rate'</span>] / <span class="string">100</span>)) / df[<span class="string">'person_income'</span>]
df[<span class="string">'interest_burden'</span>] = df[<span class="string">'interest_burden'</span>].fillna(<span class="string">0</span>)</code>
            </div>

            <h3>Step 1: Remove Outliers</h3>
            <div class="info-box">
                <p><strong>What This Does:</strong></p>
                <ul>
                    <li>Filters out records where <code>person_age > 100</code></li>
                    <li>These are considered outliers (impossible ages)</li>
                    <li>Outliers can hurt model performance</li>
                </ul>
                <p style="margin-top: 1rem;"><strong>Why This Matters:</strong> Removing unrealistic data helps the model learn better patterns from valid examples.</p>
            </div>

            <h3>Step 2: Feature Engineering - interest_burden â­</h3>
            <div class="highlight-box">
                <h3>ğŸ”‘ Creating interest_burden</h3>
                <p><strong>Formula:</strong></p>
                <div class="code-block" style="background: rgba(80, 200, 120, 0.1); border-left: 4px solid var(--emerald-green);">
<code>interest_burden = (loan_amnt Ã— (loan_int_rate / 100)) / person_income</code>
                </div>
                <p style="margin-top: 1rem;"><strong>What It Represents:</strong></p>
                <ul>
                    <li>Shows what percentage of annual income goes toward loan interest payments</li>
                    <li>Lower values = Lower financial burden = Lower risk</li>
                    <li>This single feature captures an important financial relationship</li>
                </ul>
            </div>

            <div class="info-box">
                <h3>Example Calculation:</h3>
                <ul>
                    <li>Loan amount: $10,000</li>
                    <li>Interest rate: 5%</li>
                    <li>Annual income: $50,000</li>
                </ul>
                <p style="margin-top: 1rem;"><strong>Calculation:</strong></p>
                <ul>
                    <li>Annual interest = $10,000 Ã— (5 / 100) = $500</li>
                    <li>interest_burden = $500 / $50,000 = 0.01 (or 1%)</li>
                </ul>
            </div>

            <h3>Step 3: Handle Missing Values</h3>
            <div class="code-block">
<code>df[<span class="string">'interest_burden'</span>] = df[<span class="string">'interest_burden'</span>].fillna(<span class="string">0</span>)</code>
            </div>
            <div class="info-box">
                <p><strong>What This Does:</strong> Fills any missing (NaN) values in <code>interest_burden</code> with 0.</p>
                <p style="margin-top: 1rem;"><strong>Why This Happens:</strong> If <code>person_income</code> is 0 or missing, division by zero would create NaN values. Setting them to 0 is a safe default.</p>
            </div>
        </div>

        <!-- Section 4: Data Splitting -->
        <div class="content-section" id="section4">
            <h2>4ï¸âƒ£ Data Splitting</h2>
            <div class="code-block">
<code><span class="comment"># 3. Ø§Ù„ØªÙ‚Ø³ÙŠÙ…</span>
X = df.drop(<span class="string">'loan_status'</span>, axis=<span class="string">1</span>)
y = df[<span class="string">'loan_status'</span>]</code>
            </div>

            <div class="info-box">
                <h3>What This Does:</h3>
                <ul>
                    <li><strong>X (Features):</strong> All columns except <code>loan_status</code> - these are the input features</li>
                    <li><strong>y (Target):</strong> The <code>loan_status</code> column - this is what we want to predict</li>
                </ul>
            </div>

            <div class="highlight-box">
                <h3>ğŸ’¡ Note About Train/Test Split</h3>
                <p>
                    This script trains on the <strong>entire dataset</strong> (no train/test split). The comment says:
                    <em>"Ù†Ø³ØªØ®Ø¯Ù… ÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…ØŒ Ù‡Ù†Ø§ Ù„Ù„Ø³Ø±Ø¹Ø© Ø¯Ø±Ø¨Ù†Ø§ ÙˆÙƒØ£Ù†Ù†Ø§ Ù†Ø¬Ù‡Ø² Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"</em>
                </p>
                <p style="margin-top: 1rem;">
                    <strong>Translation:</strong> "We use all data or splitting, here for speed we trained as if preparing the final product"
                </p>
                <p style="margin-top: 1rem;">
                    <strong>Why:</strong> For production deployment, sometimes you train on all available data to maximize model performance.
                </p>
            </div>
        </div>

        <!-- Section 5: Preprocessing Pipeline -->
        <div class="content-section" id="section5">
            <h2>5ï¸âƒ£ Preprocessing Pipeline</h2>
            <p>We create separate preprocessing pipelines for numerical and categorical features.</p>

            <h3>Step 1: Identify Feature Types</h3>
            <div class="code-block">
<code>numeric_features = X.select_dtypes(include=[<span class="string">'int64'</span>, <span class="string">'float64'</span>]).columns
categorical_features = X.select_dtypes(include=[<span class="string">'object'</span>, <span class="string">'category'</span>]).columns</code>
            </div>
            <div class="info-box">
                <p><strong>What This Does:</strong></p>
                <ul>
                    <li><strong>numeric_features:</strong> Automatically finds all numeric columns (int64, float64)</li>
                    <li><strong>categorical_features:</strong> Automatically finds all text/category columns (object, category)</li>
                </ul>
                <p style="margin-top: 1rem;"><strong>Why This Matters:</strong> Different feature types need different preprocessing steps.</p>
            </div>

            <h3>Step 2: Numerical Transformer Pipeline</h3>
            <div class="code-block">
<code>numeric_transformer = Pipeline(steps=[
    (<span class="string">'imputer'</span>, SimpleImputer(strategy=<span class="string">'median'</span>)),
    (<span class="string">'scaler'</span>, StandardScaler())
])</code>
            </div>
            <div class="info-box">
                <h4>For Numerical Features:</h4>
                <ol>
                    <li><strong>SimpleImputer (median):</strong> Fills missing values with the median (middle value) of that column</li>
                    <li><strong>StandardScaler:</strong> Normalizes values to have mean=0 and std=1 (puts everything on the same scale)</li>
                </ol>
                <p style="margin-top: 1rem;"><strong>Why median instead of mean?</strong> Median is more robust to outliers than mean.</p>
            </div>

            <h3>Step 3: Categorical Transformer Pipeline</h3>
            <div class="code-block">
<code>categorical_transformer = Pipeline(steps=[
    (<span class="string">'imputer'</span>, SimpleImputer(strategy=<span class="string">'most_frequent'</span>)),
    (<span class="string">'onehot'</span>, OneHotEncoder(handle_unknown=<span class="string">'ignore'</span>))
])</code>
            </div>
            <div class="info-box">
                <h4>For Categorical Features:</h4>
                <ol>
                    <li><strong>SimpleImputer (most_frequent):</strong> Fills missing values with the most common value (mode)</li>
                    <li><strong>OneHotEncoder:</strong> Converts text categories into numbers (0s and 1s)</li>
                    <li><strong>handle_unknown='ignore':</strong> If a new category appears during prediction, ignore it instead of erroring</li>
                </ol>
            </div>

            <h3>Step 4: Combine Transformers</h3>
            <div class="code-block">
<code>preprocessor = ColumnTransformer(
    transformers=[
        (<span class="string">'num'</span>, numeric_transformer, numeric_features),
        (<span class="string">'cat'</span>, categorical_transformer, categorical_features)
    ])</code>
            </div>
            <div class="highlight-box">
                <h3>ğŸ”§ ColumnTransformer Explained</h3>
                <p><strong>What It Does:</strong> Applies different preprocessing to different column types:</p>
                <ul>
                    <li>Numeric columns â†’ numeric_transformer (impute + scale)</li>
                    <li>Categorical columns â†’ categorical_transformer (impute + encode)</li>
                </ul>
                <p style="margin-top: 1rem;"><strong>Result:</strong> All features are processed and ready for the model in one step!</p>
            </div>
        </div>

        <!-- Section 6: Model Training -->
        <div class="content-section" id="section6">
            <h2>6ï¸âƒ£ Model Training â­</h2>
            <div class="code-block">
<code><span class="comment"># 5. Ø§Ù„ØªØ¯Ø±ÙŠØ¨</span>
model = Pipeline(steps=[
    (<span class="string">'preprocessor'</span>, preprocessor),
    (<span class="string">'classifier'</span>, RandomForestClassifier(
        n_estimators=<span class="string">100</span>, 
        class_weight=<span class="string">'balanced'</span>, 
        random_state=<span class="string">42</span>
    ))
])

model.fit(X, y)</code>
            </div>

            <div class="highlight-box">
                <h3>ğŸ¯ Complete Pipeline</h3>
                <p>The model is a Pipeline with two steps:</p>
                <ol>
                    <li><strong>preprocessor:</strong> Handles all data preprocessing</li>
                    <li><strong>classifier:</strong> Random Forest model that makes predictions</li>
                </ol>
                <p style="margin-top: 1rem;"><strong>Why Use Pipeline?</strong> Ensures preprocessing is applied consistently during training AND prediction.</p>
            </div>

            <h3>Random Forest Parameters:</h3>
            <div class="info-box">
                <ul>
                    <li>
                        <strong>n_estimators=100:</strong> Creates 100 decision trees. More trees = better accuracy, but slower training.
                    </li>
                    <li>
                        <strong>class_weight='balanced':</strong> â­ <strong>This is important!</strong> Automatically adjusts weights to handle imbalanced data.
                        <ul style="margin-top: 0.5rem;">
                            <li>Our dataset has 78% Safe loans and 22% Risky loans</li>
                            <li>'balanced' gives more weight to the minority class (Risky)</li>
                            <li>Helps the model learn to predict risky loans better</li>
                        </ul>
                    </li>
                    <li>
                        <strong>random_state=42:</strong> Ensures reproducible results (same random seed every time)
                    </li>
                </ul>
            </div>

            <div class="highlight-box">
                <h3>ğŸ’¡ class_weight='balanced' Explained</h3>
                <p><strong>Problem:</strong> Imbalanced dataset (78% Safe, 22% Risky)</p>
                <p><strong>Without class_weight:</strong> Model might ignore the minority class and always predict "Safe"</p>
                <p><strong>With class_weight='balanced':</strong></p>
                <ul>
                    <li>Automatically calculates weights: Safe = 0.64, Risky = 2.28</li>
                    <li>Model pays more attention to risky loans during training</li>
                    <li>Better at detecting risky applicants (which is what we want!)</li>
                </ul>
            </div>

            <h3>The Training Process</h3>
            <div class="info-box">
                <p>When <code>model.fit(X, y)</code> is called:</p>
                <ol>
                    <li>Preprocessor transforms the data (impute, scale, encode)</li>
                    <li>Random Forest builds 100 decision trees</li>
                    <li>Each tree learns patterns from the data</li>
                    <li>Trees vote together to make predictions</li>
                    <li>class_weight ensures balanced learning</li>
                </ol>
                <p style="margin-top: 1rem;"><strong>Training Time:</strong> Usually takes 1-5 minutes depending on your computer and dataset size.</p>
            </div>
        </div>

        <!-- Section 7: Model Saving -->
        <div class="content-section" id="section7">
            <h2>7ï¸âƒ£ Model Saving</h2>
            <div class="code-block">
<code><span class="comment"># 6. Ø§Ù„Ø­ÙØ¸ (Ù‡Ù†Ø§ ÙŠØªÙ… Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©)</span>
<span class="comment"># Ø³ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø³Ø®Ø© Scikit-Learn Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø¬Ù‡Ø§Ø²Ùƒ</span>
joblib.dump(model, <span class="string">'credit_risk_model.pkl'</span>)

print(<span class="string">"âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ù…Ù„Ù 'credit_risk_model.pkl' Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!"</span>)
print(<span class="string">"Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ´ØºÙŠÙ„ app.py Ø¨Ø¯ÙˆÙ† Ù…Ø´Ø§ÙƒÙ„."</span>)</code>
            </div>

            <div class="info-box">
                <h3>What This Does:</h3>
                <ul>
                    <li><strong>joblib.dump():</strong> Saves the complete pipeline (preprocessor + classifier) to a file</li>
                    <li><strong>File Name:</strong> <code>credit_risk_model.pkl</code></li>
                    <li><strong>File Location:</strong> Same directory as the script</li>
                    <li><strong>Success Message:</strong> Prints confirmation in Arabic</li>
                </ul>
            </div>

            <div class="highlight-box">
                <h3>ğŸ’¾ Why Save the Complete Pipeline?</h3>
                <p>We save the <strong>entire pipeline</strong> (preprocessor + classifier), not just the model, because:</p>
                <ul>
                    <li>The preprocessor is needed for every prediction</li>
                    <li>Ensures consistent preprocessing (same as training)</li>
                    <li>Simplifies deployment - just load and use!</li>
                    <li>No need to remember preprocessing steps separately</li>
                </ul>
            </div>

            <div class="info-box">
                <h3>ğŸ“Š Expected Output:</h3>
                <div class="code-block" style="background: rgba(0, 31, 63, 0.05);">
<code>â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ...
âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ù…Ù„Ù 'credit_risk_model.pkl' Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!
Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ´ØºÙŠÙ„ app.py Ø¨Ø¯ÙˆÙ† Ù…Ø´Ø§ÙƒÙ„.</code>
                </div>
            </div>
        </div>

        <!-- Key Differences from Notebook -->
        <div class="content-section">
            <h2>ğŸ”„ Key Differences from Jupyter Notebook</h2>
            <div class="info-box">
                <h3>1. No Train/Test Split</h3>
                <p>This script trains on the entire dataset, while the notebook uses train/test split for evaluation.</p>
            </div>

            <div class="info-box">
                <h3>2. class_weight='balanced'</h3>
                <p>This script uses <code>class_weight='balanced'</code> to handle imbalanced data, which is important for production models.</p>
            </div>

            <div class="info-box">
                <h3>3. Simpler Structure</h3>
                <p>This is a standalone script - no cells, no visualization, just training and saving.</p>
            </div>

            <div class="info-box">
                <h3>4. Direct CSV Loading</h3>
                <p>Loads CSV directly from local file, not from Kaggle (unlike the notebook).</p>
            </div>
        </div>

        <!-- How to Use -->
        <div class="content-section">
            <h2>ğŸš€ How to Use This Script</h2>
            <div class="highlight-box">
                <h3>Step-by-Step Instructions:</h3>
                <ol style="line-height: 2;">
                    <li>
                        <strong>Prepare the dataset:</strong> Ensure <code>credit_risk_dataset.csv</code> is in the same folder as <code>train_model.py</code>
                    </li>
                    <li>
                        <strong>Install dependencies:</strong> Make sure you have all required libraries:
                        <div class="code-block" style="margin-top: 0.5rem;">
<code>pip install pandas scikit-learn joblib</code>
                        </div>
                    </li>
                    <li>
                        <strong>Run the script:</strong>
                        <div class="code-block" style="margin-top: 0.5rem;">
<code>python train_model.py</code>
                        </div>
                    </li>
                    <li>
                        <strong>Wait for completion:</strong> The script will:
                        <ul>
                            <li>Load and clean the data</li>
                            <li>Create the interest_burden feature</li>
                            <li>Build the preprocessing pipeline</li>
                            <li>Train the Random Forest model</li>
                            <li>Save the model to <code>credit_risk_model.pkl</code></li>
                        </ul>
                    </li>
                    <li>
                        <strong>Use the model:</strong> The saved model can now be loaded in <code>app.py</code>
                    </li>
                </ol>
            </div>

            <div class="info-box">
                <h3>âš ï¸ Important Notes:</h3>
                <ul>
                    <li>The script will <strong>overwrite</strong> any existing <code>credit_risk_model.pkl</code> file</li>
                    <li>Training takes several minutes depending on your computer</li>
                    <li>Make sure you have enough RAM (the dataset is ~32,000 rows)</li>
                    <li>After training, you can optionally run <code>shrink_model.py</code> to compress the file</li>
                </ul>
            </div>
        </div>

        <!-- Complete Workflow -->
        <div class="content-section">
            <h2>ğŸ”„ Complete Training Workflow</h2>
            <div class="highlight-box">
                <ol style="line-height: 2;">
                    <li><strong>Load Data</strong> â†’ Read CSV file</li>
                    <li><strong>Clean Data</strong> â†’ Remove outliers (age > 100)</li>
                    <li><strong>Feature Engineering</strong> â†’ Create <code>interest_burden</code> feature</li>
                    <li><strong>Split Features/Target</strong> â†’ Separate X (features) and y (target)</li>
                    <li><strong>Identify Feature Types</strong> â†’ Separate numeric and categorical columns</li>
                    <li><strong>Build Preprocessing Pipelines</strong> â†’ Create transformers for each type</li>
                    <li><strong>Combine Transformers</strong> â†’ Use ColumnTransformer</li>
                    <li><strong>Create Model Pipeline</strong> â†’ Combine preprocessor + classifier</li>
                    <li><strong>Train Model</strong> â†’ Fit on entire dataset</li>
                    <li><strong>Save Model</strong> â†’ Export to <code>credit_risk_model.pkl</code></li>
                </ol>
            </div>
        </div>

        <!-- Key Takeaways -->
        <div class="content-section">
            <h2>ğŸ¯ Key Takeaways</h2>
            <div class="info-box">
                <ul style="line-height: 2;">
                    <li><strong>Standalone Script:</strong> Can be run independently to retrain the model</li>
                    <li><strong>Feature Engineering:</strong> Creates <code>interest_burden</code> to improve predictions</li>
                    <li><strong>Pipeline Approach:</strong> Ensures consistent preprocessing</li>
                    <li><strong>class_weight='balanced':</strong> Handles imbalanced dataset automatically</li>
                    <li><strong>Complete Pipeline:</strong> Saves preprocessor + model together</li>
                    <li><strong>Production Ready:</strong> Trains on full dataset for maximum performance</li>
                </ul>
            </div>
        </div>

        <!-- Related Files -->
        <div class="content-section">
            <h2>ğŸ“ Related Files</h2>
            <p>This script is part of the complete training workflow:</p>
            <ul>
                <li><strong>Credit_Risk_Dataset.ipynb:</strong> Interactive notebook version with visualization</li>
                <li><strong>train_model.py:</strong> Standalone training script (this file)</li>
                <li><strong>shrink_model.py:</strong> Compresses the trained model</li>
                <li><strong>app.py:</strong> Loads and uses the trained model</li>
            </ul>
            <div class="highlight-box">
                <h3>ğŸ”„ Complete Workflow:</h3>
                <ol>
                    <li>Train model using <code>train_model.py</code> â†’ Creates <code>credit_risk_model.pkl</code></li>
                    <li>(Optional) Compress using <code>shrink_model.py</code> â†’ Reduces file size</li>
                    <li>Deploy with <code>app.py</code> â†’ Loads model and makes predictions</li>
                </ol>
            </div>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="footer-content">
            <h3>Connect With Me</h3>
            <p>Follow me on social media for more projects and updates</p>
            <div class="social-links">
                <a href="https://github.com/Tegnh" target="_blank" class="social-link github" title="GitHub">
                    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                    </svg>
                </a>
                <a href="https://x.com/6ar_t" target="_blank" class="social-link twitter" title="Twitter/X">
                    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                        <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
                    </svg>
                </a>
                <a href="https://www.linkedin.com/in/tarig-fdl-7a6599348/" target="_blank" class="social-link linkedin" title="LinkedIn">
                    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                        <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
                    </svg>
                </a>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2026 Smart Credit Risk System. Built with â¤ï¸ by Tegnh</p>
            </div>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
